{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "  Using cached tensorflow-2.12.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Using cached tensorflow_intel-2.12.0-cp38-cp38-win_amd64.whl (272.8 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\joen\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.11.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (20.4)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.8-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.4.2)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.15.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.54.0-cp38-cp38-win_amd64.whl (4.1 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.34.2)\n",
      "Collecting scipy>=1.7\n",
      "  Using cached scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Using cached ml_dtypes-0.1.0-cp38-cp38-win_amd64.whl (120 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-6.5.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\joen\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: scipy, opt-einsum, ml-dtypes, importlib-metadata, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, markdown, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.0\n",
      "    Uninstalling scipy-1.5.0:\n",
      "      Successfully uninstalled scipy-1.5.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 importlib-metadata-6.5.0 jax-0.4.8 markdown-3.4.3 ml-dtypes-0.1.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 scipy-1.10.1 tensorboard-2.12.2 tensorflow-2.12.0 tensorflow-intel-2.12.0\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install matplotlib\n",
    "# %matplotlib inline\n",
    "# %pip install keras\n",
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from  keras.models import Sequential\n",
    "from  keras.layers import Dense\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esi                  object\n",
      "age                 float64\n",
      "gender                 int8\n",
      "glucose_median      float64\n",
      "triage_vital_hr     float64\n",
      "triage_vital_sbp    float64\n",
      "dtype: object\n",
      "(11066, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('raw_prep_6k.csv') # loading dataset\n",
    "\n",
    "#unify values\n",
    "data.loc[data['gender'] == '1', 'gender'] = \"Male\"\n",
    "data.loc[data['gender'] == '0', 'gender'] = \"Female\"\n",
    "\n",
    "data.loc[data['esi'] == 'red', 'esi'] = '1'\n",
    "data.loc[data['esi'] == 'orange', 'esi'] = '2'\n",
    "data.loc[data['esi'] == 'yellow', 'esi'] = '3'\n",
    "data.loc[data['esi'] == 'green', 'esi'] = '4'\n",
    "data.loc[data['esi'] == 'white', 'esi'] = '5'\n",
    "\n",
    "#drop rows with empty values and unnecessary columns\n",
    "data = data.dropna()\n",
    "\n",
    "for key in ['gender']:\n",
    "    data[key] = pd.Categorical(data[key])\n",
    "    data[key] = data[key].cat.codes\n",
    "print(data.dtypes)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733      4\n",
      "6105     3\n",
      "4773     3\n",
      "11045    3\n",
      "1150     2\n",
      "        ..\n",
      "4860     3\n",
      "3264     3\n",
      "9847     3\n",
      "10801    3\n",
      "2732     2\n",
      "Name: esi, Length: 7746, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We split the data up into a test set and a training set, 30 - 70 %\n",
    "# train_test_split\n",
    "# First argument: x data is all data without class column\n",
    "# Second argument:  this is the class label column\n",
    "# Random state = 0: ensures the train and test splitting is deterministic. \n",
    "#Otherwise every student would get a different train test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('esi',1), \n",
    "                                                    data['esi'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# define a new scaler: \n",
    "x_scaler = MinMaxScaler()\n",
    "\n",
    "# fit the normalization on the training set: \n",
    "x_scaler.fit(X_train)\n",
    "\n",
    "# then create new and normalized training/test sets: \n",
    "X_train_norm = x_scaler.transform(X_train)\n",
    "X_test_norm = x_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_on_training_set(y_test, y_pred):\n",
    "  # print out recall and precision\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  \n",
    "  # print out confusion matrix\n",
    "  print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>glucose_median</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>gender_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6914</th>\n",
       "      <td>50.0</td>\n",
       "      <td>90.10</td>\n",
       "      <td>161.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>46.0</td>\n",
       "      <td>87.00</td>\n",
       "      <td>144.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>55.0</td>\n",
       "      <td>107.00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6983</th>\n",
       "      <td>53.0</td>\n",
       "      <td>94.78</td>\n",
       "      <td>155.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>81.0</td>\n",
       "      <td>57.42</td>\n",
       "      <td>184.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4677</th>\n",
       "      <td>55.0</td>\n",
       "      <td>103.00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>68.0</td>\n",
       "      <td>108.00</td>\n",
       "      <td>64.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>57.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>141.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>40.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>52.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>85.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3320 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  glucose_median  triage_vital_hr  triage_vital_sbp  gender_0  \\\n",
       "6914   50.0           90.10            161.0              95.0         1   \n",
       "4169   46.0           87.00            144.0             120.0         0   \n",
       "3925   55.0          107.00             61.0             119.0         0   \n",
       "6983   53.0           94.78            155.0             128.0         1   \n",
       "10912  81.0           57.42            184.0              89.0         1   \n",
       "...     ...             ...              ...               ...       ...   \n",
       "4677   55.0          103.00            140.0             133.0         0   \n",
       "808    68.0          108.00             64.0             137.0         1   \n",
       "4698   57.0          123.00            141.0             124.0         0   \n",
       "844    40.0           95.00             77.0             139.0         1   \n",
       "1303   52.0           99.00             85.0             113.0         0   \n",
       "\n",
       "       gender_1  \n",
       "6914          0  \n",
       "4169          1  \n",
       "3925          1  \n",
       "6983          0  \n",
       "10912         0  \n",
       "...         ...  \n",
       "4677          1  \n",
       "808           0  \n",
       "4698          1  \n",
       "844           0  \n",
       "1303          1  \n",
       "\n",
       "[3320 rows x 6 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Convert categorical variable into dummy/indicator variables.\"\n",
    "nX_train = pd.get_dummies(X_train, prefix=['gender'], columns=['gender'])\n",
    "ny_train = pd.get_dummies(y_train)\n",
    "final_X_test  = pd.get_dummies(X_test, prefix=['gender'], columns=['gender'])\n",
    "final_y_test  = pd.get_dummies(y_test)\n",
    "\n",
    "final_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim   = len(nX_train.columns) # number of neurons in the input layer\n",
    "n_neurons   = 8            # number of neurons in the first hidden layer\n",
    "epochs      = 100           # number of training cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras model\n",
    "model = Sequential()         # a model consisting of successive layers\n",
    "# input layer\n",
    "model.add(Dense(n_neurons, input_dim=input_dim, activation='relu'))\n",
    "# output layer, with 5 neuron\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 8)                 56        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e6f99744f0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(nX_train, ny_train, epochs=epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.6946\n",
      "test loss, test acc: [0.1151331439614296, 0.6945782899856567]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(final_X_test, final_y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(max_depth=5, min_samples_leaf=1) \n",
    "# Using default parameters\n",
    "\n",
    "model.fit(X_train, y_train)# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '3' '2' ... '3' '3' '2']\n",
      "6914     3\n",
      "4169     1\n",
      "3925     2\n",
      "6983     3\n",
      "10912    3\n",
      "        ..\n",
      "4677     3\n",
      "808      4\n",
      "4698     3\n",
      "844      3\n",
      "1303     3\n",
      "Name: esi, Length: 3320, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        31\n",
      "           2       0.51      0.53      0.52       545\n",
      "           3       0.80      0.90      0.85      2307\n",
      "           4       0.99      0.48      0.64       291\n",
      "           5       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.76      3320\n",
      "   macro avg       0.46      0.38      0.40      3320\n",
      "weighted avg       0.73      0.76      0.73      3320\n",
      "\n",
      "Confusion Matrix: \n",
      " [[   0    0   31    0    0]\n",
      " [   0  289  255    1    0]\n",
      " [   0  219 2087    1    0]\n",
      " [   0   52  100  139    0]\n",
      " [   0    5  141    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) # Predicting labels for our test set using model\n",
    "print (y_pred)\n",
    "print(y_test)\n",
    "evaluate_on_training_set(y_test, y_pred) #evaluate our model using new function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5) # Define the model with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.26      0.25        31\n",
      "           2       0.42      0.48      0.45       545\n",
      "           3       0.79      0.84      0.81      2307\n",
      "           4       0.82      0.36      0.50       291\n",
      "           5       0.30      0.11      0.16       146\n",
      "\n",
      "    accuracy                           0.70      3320\n",
      "   macro avg       0.51      0.41      0.43      3320\n",
      "weighted avg       0.70      0.70      0.69      3320\n",
      "\n",
      "Confusion Matrix: \n",
      " [[   8    3   20    0    0]\n",
      " [   2  264  271    6    2]\n",
      " [  21  288 1945   17   36]\n",
      " [   0   66  119  106    0]\n",
      " [   3   11  116    0   16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joen\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:189: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_norm, y_train) # Training the model\n",
    "\n",
    "# Evaluate the model: \n",
    "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
    "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Let's move on to a very powerful, yet fast model: Logistic Regression. Again, we start by loading the library and defining the model together with its parameters. \n",
    "\n",
    "In this case, multi_class auto will detect the number of classes automatically, C is our regularisation parameter, and solver is the optimization algorithm used to fit the model: \n",
    "* For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "* For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "* ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
    "* ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
    "* ‘saga’ also supports ‘elasticnet’ penalty\n",
    "* ‘liblinear’ does not handle no penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=1.0, multi_class='auto', solver='saga') \n",
    "# Define the model with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        31\n",
      "           2       0.43      0.23      0.30       545\n",
      "           3       0.72      0.94      0.82      2307\n",
      "           4       0.21      0.03      0.05       291\n",
      "           5       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.69      3320\n",
      "   macro avg       0.27      0.24      0.23      3320\n",
      "weighted avg       0.59      0.69      0.62      3320\n",
      "\n",
      "Confusion Matrix: \n",
      " [[   0    0   31    0    0]\n",
      " [   0  126  404   15    0]\n",
      " [   0  128 2161   18    0]\n",
      " [   0   35  247    9    0]\n",
      " [   0    4  142    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_norm, y_train) # Training the model\n",
    "\n",
    "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
    "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB #many diff NB models available\n",
    "model = GaussianNB() # Define the model with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.32      0.22        31\n",
      "           2       0.39      0.41      0.40       545\n",
      "           3       0.75      0.87      0.80      2307\n",
      "           4       0.17      0.01      0.01       291\n",
      "           5       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.67      3320\n",
      "   macro avg       0.30      0.32      0.29      3320\n",
      "weighted avg       0.60      0.67      0.63      3320\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  10    0   21    0    0]\n",
      " [   0  222  318    5    0]\n",
      " [  36  265 2001    5    0]\n",
      " [   0   72  217    2    0]\n",
      " [  12    7  127    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_norm, y_train) # Training the model\n",
    "\n",
    "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
    "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "The kernel can be: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’. If none is given, ‘rbf’ will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma='auto')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(C=10, gamma='auto', kernel='rbf')\n",
    "model.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        31\n",
      "           2       0.64      0.12      0.20       545\n",
      "           3       0.73      0.99      0.84      2307\n",
      "           4       1.00      0.27      0.42       291\n",
      "           5       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.73      3320\n",
      "   macro avg       0.47      0.27      0.29      3320\n",
      "weighted avg       0.70      0.73      0.65      3320\n",
      "\n",
      "Confusion Matrix: \n",
      " [[   0    0   31    0    0]\n",
      " [   0   64  481    0    0]\n",
      " [   0   29 2278    0    0]\n",
      " [   0    7  206   78    0]\n",
      " [   0    0  146    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_norm, y_train) # Training SVM\n",
    "\n",
    "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
    "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gridsearch\n",
    "* with kernel rbf, try varying gamma (which is a coefficient in the rbf kernel) to be 1e-3 or 1e-4; and vary C to be 1, 10, or 100.\n",
    "* with linear kernel (there is no gamma here), try varying C to be 1, 10, and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                     'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100]},\n",
    "                    {'kernel': ['linear'],\n",
    "                     'C': [1, 10, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  18 out of  18 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=SVC(), n_jobs=4,\n",
       "             param_grid=[{'C': [1, 10, 100], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100], 'kernel': ['linear']}],\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we define the grid search model for SVM:  cv=2 is 2-fold CV\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=2,\n",
    "                   scoring='accuracy', verbose=1, n_jobs=4)\n",
    "\n",
    "# train the model on the training set: \n",
    "clf.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set found on development set:\n",
      "{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'} \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        31\n",
      "           2       0.00      0.00      0.00       545\n",
      "           3       0.69      1.00      0.82      2307\n",
      "           4       0.00      0.00      0.00       291\n",
      "           5       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.69      3320\n",
      "   macro avg       0.14      0.20      0.16      3320\n",
      "weighted avg       0.48      0.69      0.57      3320\n",
      "\n",
      "Confusion Matrix: \n",
      " [[   0    0   31    0    0]\n",
      " [   0    0  545    0    0]\n",
      " [   0    0 2307    0    0]\n",
      " [   0    0  291    0    0]\n",
      " [   0    0  146    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Show best parameters: \n",
    "print(\"Best parameter set found on development set:\")\n",
    "print(clf.best_params_, '\\n')\n",
    "\n",
    "y_pred = clf.predict(X_test_norm) #create predictions\n",
    "evaluate_on_training_set(y_test, y_pred) # evaluate like we always do"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#learning rate can vary from 0 to 1; \n",
    "# and n_estimators is the number of times a model is built.\n",
    "model = AdaBoostClassifier(n_estimators=1000, learning_rate=0.01) # Define the model with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        31\n",
      "           2       0.18      0.03      0.06       545\n",
      "           3       0.73      0.93      0.82      2307\n",
      "           4       0.11      0.10      0.10       291\n",
      "           5       0.00      0.00      0.00       146\n",
      "\n",
      "    accuracy                           0.66      3320\n",
      "   macro avg       0.20      0.21      0.20      3320\n",
      "weighted avg       0.54      0.66      0.59      3320\n",
      "\n",
      "Confusion Matrix: \n",
      " [[   0    0   31    0    0]\n",
      " [   0   19  396  130    0]\n",
      " [   0   55 2140  112    0]\n",
      " [   0   26  236   29    0]\n",
      " [   0    3  140    3    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_norm, y_train) # Training the model\n",
    "\n",
    "y_pred = model.predict(X_test_norm) # Predicting labels for our test set using trained model\n",
    "evaluate_on_training_set(y_test, y_pred) #evaluate our model using newly defined function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# n_estimators is how many trees there are in the model\n",
    "model = RandomForestClassifier(n_estimators = 200) # Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.35      0.39        31\n",
      "           2       0.48      0.47      0.47       545\n",
      "           3       0.79      0.88      0.83      2307\n",
      "           4       0.86      0.50      0.63       291\n",
      "           5       0.33      0.10      0.15       146\n",
      "\n",
      "    accuracy                           0.74      3320\n",
      "   macro avg       0.58      0.46      0.50      3320\n",
      "weighted avg       0.72      0.74      0.72      3320\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  11    0   20    0    0]\n",
      " [   1  256  282    5    1]\n",
      " [  13  226 2024   18   26]\n",
      " [   0   44  100  146    1]\n",
      " [   1    7  123    1   14]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_norm, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_norm)\n",
    "evaluate_on_training_set(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca44a43a1e44d0e273a7d98ec8e46b09b842855749c72bc2b7650f4a8d63c062"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
